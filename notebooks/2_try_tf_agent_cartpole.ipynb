{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d696b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial: https://colab.research.google.com/github/tensorflow/agents/blob/master/docs/tutorials/1_dqn_tutorial.ipynb#scrollTo=N7brXNIGWXjC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0abb73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyvirtualdisplay\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.environments import tf_py_environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec138f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([ 0.0449783 ,  0.0067319 ,  0.02191332, -0.00923979], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0)})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = suite_gym.load(env_name)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e01c88",
   "metadata": {},
   "source": [
    "In the Cartpole environment:\n",
    "\n",
    "observation is an array of 4 floats: <br>\n",
    "the position and velocity of the cart <br>\n",
    "the angular position and velocity of the pole <br>\n",
    "reward is a scalar float value <br>\n",
    "action is a scalar integer with only two possible values: <br>\n",
    "0 — \"move left\" <br>\n",
    "1 — \"move right\" <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e459df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537bff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e49cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49f1d5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
       " 'observation': BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]),\n",
       " 'reward': ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
       " 'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9d1698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.01751985,  0.04434055, -0.00962096, -0.03994654], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([ 0.01840666,  0.23959914, -0.01041989, -0.33564937], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95af13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0bdaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0, dtype=int64), maximum=array(1, dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_tensor_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2de9d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fcb9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_env = suite_gym.load(env_name)\n",
    "env = tf_py_environment.TFPyEnvironment(py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85c0b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(\n",
    "        num_units,\n",
    "        activation=tf.keras.activations.relu,\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "            scale=2.0, mode='fan_in', distribution='truncated_normal')\n",
    "    )\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d1af61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    env.time_step_spec(),\n",
    "    env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce04649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              multiple                  500       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  5050      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  102       \n",
      "=================================================================\n",
      "Total params: 5,652\n",
      "Trainable params: 5,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438a9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic_pricing_comp",
   "language": "python",
   "name": "dynamic_pricing_comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
